@book{Applegate2009TSP,
  title     = {The Traveling Salesman Problem},
  subtitle  = {A Computational Study},
  author    = {Applegate, David L. and Bixby, Robert E. and Chv{\'a}tal, Vasek and Cook, William J.},
  series    = {Princeton Series in Applied Mathematics},
  year      = {2006},
  publisher = {Princeton University Press},
}

% Cite GitHub Repo
@misc{Bossek2020salesperson,
  author = {Bossek, Jakob},
  title = {Salesperson},
  subtitle = {Comprehensive Collection of Functions for Solving and Analyzing Travelling Salesperson Problems in R},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jakobbossek/salesperson}},
  commit = {eaf397879a35de717b57373966dc8c547c5adafb}
}

@Manual{bossek2017ecrpackage,
  Title       = {{ecr: Evolutionary Computation in R}},
  Author      = {Bossek, Jakob},
  Note        = {\texttt{R}-package version 2.1.0},
  Year        = {2017}
}

@inproceedings{Bossek2019evolv,
  author = {Bossek, Jakob and Kerschke, Pascal and Neumann, Aneta and Wagner, Markus and Neumann, Frank and Trautmann, Heike},
  title = {Evolving Diverse TSP Instances by Means of Novel and Creative Mutation Operators},
  booktitle = {Proceedings of the 15th ACM/SIGEVO Conference on Foundations of Genetic Algorithms},
  series = {FOGA ’19},
  publisher = {Association for Computing Machinery},
  location = {Potsdam, Germany},
  year = {2019},
  pages = {58-–71},
  doi = {10.1145/3299904.3340307}
}

@PhdThesis{carnein2020ml,
  Author      = {Carnein, Matthias},
  Title       = {Machine Learning on Data Streams -- Improving the Applicability and Performance of Stream Clustering Algorithms},
  School      = {Department of Information Systems, University of M{\"u}nster, M{\"u}nster, Germany},
  Year        = {2020}
}

@TechReport{das2010problem,
  Author      = {Das, Swagatam and Suganthan, Ponnuthurai N.},
  Title       = {{Problem Definitions and Evaluation Criteria for CEC 2011 Competition on Testing Evolutionary Algorithms on Real World Optimization Problems}},
  Institution = {Jadavpur University, Nanyang Technological University, Kolkata},
  Year        = {2010},
}


@Article{Kerschke2019aas,
  Author  = {Kerschke, Pascal and Hoos, Holger H. and Neumann, Frank and Trautmann, Heike},
  Title   = {{Automated Algorithm Selection: Survey and Perspectives}},
  Journal = {Evolutionary Computation (ECJ)},
  Year    = {2019},
  Volume  = {27},
  DOI     = {10.1162/evco_a_00242},
  Number  = {1},
  Pages   = {3--45},
  Publisher = {MIT Press}
}

% Cite Website as misc.  Note that an author must be present.
% In line with APA styling, we repeat words from the title.
% See: https://apastyle.apa.org/learn/faqs/web-page-no-author
% Note the double braces to prevent usual name parsing.
@misc{deppenleerzeichen,
  author = {{Leerzeichen in Komposita}},
  title = {{Leerzeichen in Komposita --- Wikipedia, Die freie Enzyklop{\"a}die}},
  url = {https://de.wikipedia.org/wiki/Leerzeichen_in_Komposita},
  year = 2019,
  urldate = {2019-08-08}
}

@misc{kommaregeln,
  author = {{Bibliographisches Institut GmbH}},
  title = {{Komma}},
  url = {https://www.duden.de/sprachwissen/rechtschreibregeln/komma},
  urldate = {2019-08-08},
  year = 2019,
}

@misc{overleafprivacy,
  author = {{Overleaf}},
  title = {{Overleaf Privacy Notice}},
  year = 2021,
  url = {https://www.overleaf.com/legal#Privacy},
  urldate = {2021-03-12}
}

@misc{Fear2020booktabs,
  author = {Fear, Simon},
  title = {{booktabs. Publication quality tables in \LaTeX}},
  year = {2020},
  publisher = {Comprehensive TEX Archive Network (CTAN)},
  url = {https://www.ctan.org/pkg/booktabs?lang=en},
  urldate = {2020-09-10}
}

@misc{Janos2020algorithmicx,
  author = {J\'{a}nos, Sz\'{a}sz},
  title = {{algorithmicx – The algorithmic style you always wanted}},
  year = {2020},
  publisher = {Comprehensive TEX Archive Network (CTAN)},
  url = {https://www.ctan.org/pkg/algorithmicx},
  urldate = {2020-09-10}
}

@misc{Poore2020minted,
  author = {Geoffrey M. Poore},
  title = {{The minted package: Highlighted source code in \LaTeX}},
  year = {2017},
  publisher = {Comprehensive TEX Archive Network (CTAN)},
  url = {https://www.ctan.org/pkg/minted},
  urldate = {2020-09-10}
}

@article{Codd1970relational,
author = {Codd, E. F.},
title = {A Relational Model of Data for Large Shared Data Banks},
year = {1970},
issue_date = {June 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/362384.362685},
doi = {10.1145/362384.362685},
abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
journal = {Commun. ACM},
month = jun,
pages = {377–387},
numpages = {11},
keywords = {data organization, derivability, retrieval language, data base, data integrity, redundancy, consistency, networks of data, data bank, predicate calculus, security, hierarchies of data, composition, join, relations, data structure}
}

@book{Rusell2003artificial,
author = {Russell, Stuart J. and Norvig, Peter},
title = {Artificial Intelligence: A Modern Approach},
year = {2003},
isbn = {0137903952},
publisher = {Pearson Education},
edition = {2},
abstract = {From the Publisher:Intelligent Agents - Stuart Russell and Peter Norvig show how intelligent agents can be built using AI methods, and explain how different agent designs are appropriate depending on the nature of the task and environment. Artificial Intelligence: A Modern Approach is the first AI text to present a unified, coherent picture of the field. The authors focus on the topics and techniques that are most promising for building and analyzing current and future intelligent systems. The material is comprehensive and authoritative, yet cohesive and readable. State of the Art - This book covers the most effective modern techniques for solving real problems, including simulated annealing, memory-bounded search, global ontologies, dynamic belief networks, neural networks, adaptive probabilistic networks, inductive logic programming, computational learning theory, and reinforcement learning. Leading edge AI techniques are integrated into intelligent agent designs, using examples and exercises to lead students from simple, reactive agents to advanced planning agents with natural language capabilities.}
}


@inproceedings{Goodfellow2014gan,
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative Adversarial Nets},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2672–2680},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'14}
}

@book{Goodfellow2016deep,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
title = {Deep Learning},
year = {2016},
isbn = {0262035618},
publisher = {The MIT Press},
abstract = {"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject." -- Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.}
}

@BOOK{OberschelpVossen,
  title = {Rechneraufbau und Rechnerstrukturen},
  publisher = {Oldenburg Wissenschaftsverlag},
  year = {2006},
  author = {W. Oberschelp and G. Vossen},
  edition = {10th}
}

@book{Bergener2019wissenschaftliches,
  title={Wissenschaftliches Arbeiten im Wirtschaftsinformatik\hyphen{}Studium: Leitfaden f{\"u}r die erfolgreiche Abschlussarbeit},
  author={Bergener, Katrin and Clever, Nico and Stein, Armin},
  year={2019},
  publisher={Springer},
  doi={10.1007/978-3-662-57949-7}
}

@book{Brink2013anfertigung,
  title={Anfertigung wissenschaftlicher Arbeiten: Ein prozessorientierter Leitfaden zur Erstellung von Bachelor-, Master-und Diplomarbeiten},
  author={Brink, Alfred},
  year={2013},
  publisher={Springer-Verlag},
  doi={10.1007/978-3-8349-4397-2}
}
